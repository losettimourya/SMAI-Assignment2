{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87db81ba-9938-4318-a7e0-e991d6217ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy import random\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, k, dim, init_mu=None, init_sigma=None, init_pi=None, colors=None, epsilon = 1e-10):\n",
    "        '''\n",
    "        Define a model with known number of clusters and dimensions.\n",
    "        input:\n",
    "            - k: Number of Gaussian clusters\n",
    "            - dim: Dimension \n",
    "            - init_mu: initial value of mean of clusters (k, dim)\n",
    "                       (default) random from uniform[-10, 10]\n",
    "            - init_sigma: initial value of covariance matrix of clusters (k, dim, dim)\n",
    "                          (default) Identity matrix for each cluster\n",
    "            - init_pi: initial value of cluster weights (k,)\n",
    "                       (default) equal value to all cluster i.e. 1/k\n",
    "            - colors: Color valu for plotting each cluster (k, 3)\n",
    "                      (default) random from uniform[0, 1]\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.dim = dim\n",
    "        if(init_mu is None):\n",
    "            init_mu = np.random.rand(k, dim)*20 - 10\n",
    "        self.mu = init_mu\n",
    "        if init_sigma is None:\n",
    "            init_sigma = np.zeros((k, dim, dim))\n",
    "            for i in range(k):\n",
    "                init_sigma[i] = np.eye(dim) + epsilon * np.identity(dim)\n",
    "\n",
    "        self.sigma = init_sigma\n",
    "        if(init_pi is None):\n",
    "            init_pi = np.ones(self.k)/self.k\n",
    "        self.pi = init_pi\n",
    "        # print(init_mu)\n",
    "        # print(self.pi)\n",
    "        print(self.sigma[0][0][0])\n",
    "        if(colors is None):\n",
    "            colors = np.random.rand(k, 3)\n",
    "        self.colors = colors\n",
    "    def fit(self, num_iterations=1000, tolerance=1e-20):\n",
    "        for iteration in range(num_iterations):\n",
    "            self.e_step()\n",
    "            prev_mu = np.array(self.mu.copy())\n",
    "            prev_sigma = np.array(self.sigma.copy())\n",
    "            prev_pi = np.array(self.pi.copy())\n",
    "            \n",
    "            self.m_step()\n",
    "\n",
    "            delta_mu = np.linalg.norm(self.mu - prev_mu)\n",
    "            delta_sigma = np.linalg.norm(self.sigma - prev_sigma)\n",
    "            delta_pi = np.linalg.norm(self.pi - prev_pi)\n",
    "            print(delta_mu,delta_pi,delta_sigma)\n",
    "\n",
    "            if delta_mu < tolerance and delta_sigma < tolerance and delta_pi < tolerance:\n",
    "                print(f\"Converged after {iteration + 1} iterations.\")\n",
    "                break\n",
    "\n",
    "            log_likelihood = self.log_likelihood(self.data+1e-10)\n",
    "            print(f\"Iteration {iteration + 1}, Log Likelihood: {log_likelihood}\")\n",
    "    def init_em(self, X):\n",
    "        '''\n",
    "        Initialization for EM algorithm.\n",
    "        input:\n",
    "            - X: data (batch_size, dim)\n",
    "        '''\n",
    "        self.data = X\n",
    "        self.num_points = X.shape[0]\n",
    "        # identity_like_matrix = 1e-10 * np.identity(self.dim)\n",
    "        self.z = np.zeros((self.num_points, self.k))+ (1e-10)\n",
    "        # self.z = np.tile(identity_like_matrix, (self.num_points, self.k))\n",
    "    \n",
    "    def e_step(self):\n",
    "        '''\n",
    "        E-step of EM algorithm.\n",
    "        '''\n",
    "        for i in range(self.k):\n",
    "            print(self.sigma[i])\n",
    "            print(self.mu[i])\n",
    "            epsilon = 1e-10\n",
    "            cov_matrix = self.sigma[i] + epsilon * np.identity(self.sigma[i].shape[0])\n",
    "            print(multivariate_normal.pdf(self.data, mean=self.mu[i], cov=cov_matrix))\n",
    "            self.z[:, i] = self.pi[i] * multivariate_normal.pdf(self.data, mean=self.mu[i], cov=cov_matrix)\n",
    "        # print(self.z)\n",
    "        self.z /= (self.z.sum(axis=1, keepdims=True)+1e-10)\n",
    "        # print(self.z)\n",
    "    def m_step(self):\n",
    "        '''\n",
    "        M-step of EM algorithm.\n",
    "        '''\n",
    "        sum_z = self.z.sum(axis=0)\n",
    "        self.pi = sum_z / self.num_points\n",
    "        self.mu = np.matmul(self.z.T, self.data)\n",
    "        self.mu /= (sum_z[:, None]+1e-10)\n",
    "        print(\"M step\")\n",
    "        print(self.mu)\n",
    "        for i in range(self.k):\n",
    "            j = np.expand_dims(self.data, axis=1) - self.mu[i]\n",
    "            s = np.matmul(j.transpose([0, 2, 1]), j)\n",
    "            self.sigma[i] = np.matmul(s.transpose(1, 2, 0), self.z[:, i]) + 1e-10 * np.identity(self.dim)\n",
    "            self.sigma[i] /= (sum_z[i]+1e-10)\n",
    "            \n",
    "    def log_likelihood(self, X):\n",
    "        '''\n",
    "        Compute the log-likelihood of X under current parameters\n",
    "        input:\n",
    "            - X: Data (batch_size, dim)\n",
    "        output:\n",
    "            - log-likelihood of X: Sum_n Sum_k log(pi_k * N( X_n | mu_k, sigma_k ))\n",
    "        '''\n",
    "        ll = []\n",
    "        for d in X:\n",
    "            tot = 0\n",
    "            for i in range(self.k):\n",
    "                epsilon = 1e-10\n",
    "                cov_matrix = self.sigma[i] + epsilon * np.identity(self.sigma[i].shape[0])\n",
    "                tot += self.pi[i] * multivariate_normal.pdf(d, mean=self.mu[i], cov=cov_matrix)\n",
    "            ll.append(np.log(tot))\n",
    "        return np.sum(ll)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb5a64e6-deb3-47ff-ac27-f525fc2e16fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 67 ...  2  1  2]\n",
      " [ 1  1 22 ...  1  1  2]\n",
      " [ 0  0 49 ...  1  0  0]\n",
      " ...\n",
      " [ 0  0 31 ...  0  0  0]\n",
      " [ 1  1 24 ...  1  0  0]\n",
      " [ 0  0 25 ...  0  0  0]]\n",
      "1.0000000001\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[-2.50919762  9.01428613  4.63987884  1.97316968 -6.87962719 -6.88010959\n",
      " -8.83832776]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[ 7.32352292  2.02230023  4.16145156 -9.58831011  9.39819704  6.64885282\n",
      " -5.75321779]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "M step\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "24.866974876893252 0.7071067811865476 3.741657696360062e-10\n",
      "Iteration 1, Log Likelihood: -inf\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_976899/1400064550.py:121: RuntimeWarning: divide by zero encountered in log\n",
      "  ll.append(np.log(tot))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "M step\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "0.0 0.0 0.0\n",
      "Converged after 2 iterations.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Extract the relevant features (age, income, etc.) as NumPy array\n",
    "X = data[['Gender', 'Marital status', 'Age', 'Income', 'Education', 'Occupation', 'Settlement size', ]].values\n",
    "X = np.array(X)\n",
    "print(X)\n",
    "# Instantiate the GMM model\n",
    "n_components = 10  # You can vary the number of components\n",
    "n_samples, n_features = X.shape\n",
    "np.random.seed(42)\n",
    "gmm = GMM(2,7)\n",
    "# Fit the data\n",
    "gmm.init_em(X)\n",
    "gmm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2fd11-6167-44d1-b67a-5d3bd8b40301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
